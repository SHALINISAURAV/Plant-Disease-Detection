# -*- coding: utf-8 -*-
"""PlantDisease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V_mfzO1lX3XDlLaHNutzU_7ebK7iK1Vi

# Potato Leaf Disease Detection - Complete Documentation

## üìã Project Overview

This project implements a deep learning system to detect potato leaf diseases using AlexNet and other machine learning models. It can classify potato leaves into three categories:
‚Ä¢‚Å†  ‚Å†*Early Blight*: Fungal disease causing dark spots
‚Ä¢‚Å†  ‚Å†*Late Blight*: Serious disease causing rapid plant death
‚Ä¢‚Å†  ‚Å†*Healthy*: Normal, disease-free leaves

## üéØ Key Features

‚Ä¢‚Å†  ‚Å†*AlexNet Implementation*: Custom implementation of the famous AlexNet architecture
‚Ä¢‚Å†  ‚Å†*Multiple Models*: Compare AlexNet, Custom CNN, VGG16, and ResNet50
‚Ä¢‚Å†  ‚Å†*Data Augmentation*: Improves model generalization
‚Ä¢‚Å†  ‚Å†*Comprehensive Visualization*: Training curves, confusion matrices, predictions
‚Ä¢‚Å†  ‚Å†*Easy Inference*: Predict disease from new images
‚Ä¢‚Å†  ‚Å†*High Accuracy*: Achieves 99%+ accuracy on the dataset

---
"""

import tensorflow as tf
print("TensorFlow Version:", tf.__version__)
print("GPU Available:", tf.config.list_physical_devices('GPU'))
print("GPU Name:", tf.test.gpu_device_name() if tf.test.gpu_device_name() else "No GPU found")

# STEP 2: INSTALL REQUIRED LIBRARIES
!pip install -q opencv-python
!pip install -q scikit-learn
!pip install -q seaborn

print(" All libraries installed successfully!")

from google.colab import drive
drive.mount('/content/drive')

print(" Google Drive mounted successfully!")
print("You can now access files at: /content/drive/MyDrive/")

# STEP 4: UPLOAD DATASET TO COLAB
from google.colab import files
import zipfile
import os

print("Click 'Choose Files' and select your dataset ZIP file...")
uploaded = files.upload()

# Extract the uploaded ZIP
for filename in uploaded.keys():
    print(f'Extracting {filename}...')
    with zipfile.ZipFile(filename, 'r') as zip_ref:
        zip_ref.extractall('/content/')
    print(f' {filename} extracted successfully!')

# Verify extraction
print("\n Contents of /content/:")
!ls -la /content

# STEP 5: VERIFY DATASET STRUCTURE
# Check if your dataset has the correct structure

def verify_dataset_structure(base_path):
    """Verify and display dataset structure"""
    print(f"\n Checking dataset at: {base_path}\n")

    expected_folders = [
        'Potato___Early_blight',
        'Potato___Late_blight',
        'Potato___healthy'
    ]

    if not os.path.exists(base_path):
        print(f" ERROR: Path does not exist: {base_path}")
        print("\n Available directories in /content/:")
        !ls -la /content/
        return False

    print(f" Base path exists: {base_path}\n")
    print(" Directory structure:")

    all_good = True
    for folder in expected_folders:
        folder_path = os.path.join(base_path, folder)
        if os.path.exists(folder_path):
            num_images = len([f for f in os.listdir(folder_path)
                            if f.endswith(('.jpg', '.jpeg', '.png', '.JPG'))])
            print(f"   {folder}: {num_images} images")
        else:
            print(f"   {folder}: NOT FOUND")
            all_good = False

    if all_good:
        print("\n Dataset structure is correct!")
    else:
        print("\n Dataset structure needs fixing!")
        print("\n Try these fixes:")
        print("1. Check if folders have different names")
        print("2. Verify ZIP extraction completed")
        print("3. List actual contents:")
        !ls -R {base_path}

    return all_good

# Verify your dataset (UPDATE PATH IF NEEDED)
DATASET_PATH = '/content/Potato' # Updated path
verify_dataset_structure(DATASET_PATH)

"""**IMPORT LIBRARIES**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.applications import VGG16, ResNet50
import cv2
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')
print("GPU Available:", tf.config.list_physical_devices('GPU'))

"""** DATA LOADING AND PREPROCESSING**"""

class PotatoDataLoader:
    """
    Handles loading and preprocessing of potato leaf disease images.
    Expects directory structure:
    dataset/
        ‚îú‚îÄ‚îÄ Potato___Early_blight/
        ‚îú‚îÄ‚îÄ Potato___Late_blight/
        ‚îî‚îÄ‚îÄ Potato___healthy/
    Or dataset/Train, dataset/Test, dataset/Valid with above subfolders.
    """

    def __init__(self, data_dir, img_size=(227, 227)):
        self.data_dir = data_dir
        self.img_size = img_size
        self.classes = ['Early_Blight', 'Late_Blight', 'Healthy']

    def load_data(self):
        """Load images and labels from directory, searching recursively if needed"""
        images = []
        labels = []

        # Map folder names to simplified class names
        class_mapping = {
            'Potato___Early_blight': 'Early_Blight',
            'Potato___Late_blight': 'Late_Blight',
            'Potato___healthy': 'Healthy'
        }

        found_folders = set()

        # Walk through the data directory to find class folders
        for root, dirs, files in os.walk(self.data_dir):
            for folder in dirs:
                if folder in class_mapping:
                    folder_path = os.path.join(root, folder)
                    class_name = class_mapping[folder]
                    print(f"Loading {class_name} images from {folder_path}...")
                    found_folders.add(folder)

                    for img_name in os.listdir(folder_path):
                        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                            img_path = os.path.join(folder_path, img_name)
                            try:
                                img = cv2.imread(img_path)
                                if img is not None:
                                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                                    img = cv2.resize(img, self.img_size)
                                    images.append(img)
                                    labels.append(class_name)
                                else:
                                    print(f"Warning: Could not read image {img_path}")
                            except Exception as e:
                                print(f"Error loading image {img_path}: {e}")


        # Check if all expected folders were found
        for expected_folder in class_mapping:
            if expected_folder not in found_folders:
                 print(f"Warning: Expected folder '{expected_folder}' not found within {self.data_dir} or its subdirectories.")


        return np.array(images), np.array(labels)

    def prepare_data(self, test_size=0.2, val_size=0.1):
        """Load and split data into train, validation, and test sets"""
        X, y = self.load_data()

        if len(X) == 0:
            print("Error: No images loaded. Please check your dataset path and structure.")
            return (np.array([]), np.array([])), (np.array([]), np.array([])), (np.array([]), np.array([])), LabelEncoder()


        # Normalize images
        X = X.astype('float32') / 255.0

        # Encode labels
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)

        # Split data: train, temp (validation + test)
        # Ensure there are enough samples for splitting
        if len(X) < 2:
             print(f"Error: Not enough samples ({len(X)}) to perform train/test split.")
             return (np.array([]), np.array([])), (np.array([]), np.array([])), (np.array([]), np.array([])), le


        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y_encoded, test_size=(test_size + val_size),
            random_state=42, stratify=y_encoded
        )

        # Split temp into validation and test
        val_ratio = val_size / (test_size + val_size)
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=(1 - val_ratio),
            random_state=42, stratify=y_temp
        )

        print(f"\nDataset Statistics:")
        print(f"Total images: {len(X)}")
        print(f"Training: {len(X_train)}")
        print(f"Validation: {len(X_val)}")
        print(f"Testing: {len(X_test)}")
        print(f"Classes: {le.classes_}")

        return (X_train, y_train), (X_val, y_val), (X_test, y_test), le

"""**ALEXNET ARCHITECTURE**"""

class AlexNet:
    """
    AlexNet Architecture for Potato Leaf Disease Detection

    Architecture:
    - Conv1: 96 filters, 11x11, stride 4, ReLU, MaxPool 3x3
    - Conv2: 256 filters, 5x5, ReLU, MaxPool 3x3
    - Conv3: 384 filters, 3x3, ReLU
    - Conv4: 384 filters, 3x3, ReLU
    - Conv5: 256 filters, 3x3, ReLU, MaxPool 3x3
    - FC1: 4096 neurons, ReLU, Dropout
    - FC2: 4096 neurons, ReLU, Dropout
    - Output: 3 classes (Softmax)
    """

    @staticmethod
    def build(input_shape=(227, 227, 3), num_classes=3):
        model = models.Sequential([
            # Layer 1: Convolution + ReLU + Max Pooling
            layers.Conv2D(96, (11, 11), strides=4, activation='relu',
                         input_shape=input_shape, padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((3, 3), strides=2),

            # Layer 2: Convolution + ReLU + Max Pooling
            layers.Conv2D(256, (5, 5), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((3, 3), strides=2),

            # Layer 3: Convolution + ReLU
            layers.Conv2D(384, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),

            # Layer 4: Convolution + ReLU
            layers.Conv2D(384, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),

            # Layer 5: Convolution + ReLU + Max Pooling
            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((3, 3), strides=2),

            # Flatten
            layers.Flatten(),

            # Fully Connected Layer 1
            layers.Dense(4096, activation='relu'),
            layers.Dropout(0.5),

            # Fully Connected Layer 2
            layers.Dense(4096, activation='relu'),
            layers.Dropout(0.5),

            # Output Layer
            layers.Dense(num_classes, activation='softmax')
        ])

        return model

"""**ADDITIONAL CNN MODELS**"""

class CustomCNN:
    """Simple Custom CNN for comparison"""

    @staticmethod
    def build(input_shape=(227, 227, 3), num_classes=3):
        model = models.Sequential([
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
            layers.MaxPooling2D((2, 2)),

            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),

            layers.Conv2D(128, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),

            layers.Flatten(),
            layers.Dense(128, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(num_classes, activation='softmax')
        ])

        return model

class TransferLearningModels:
    """Pre-trained models with transfer learning"""

    @staticmethod
    def build_vgg16(input_shape=(227, 227, 3), num_classes=3):
        base_model = VGG16(weights='imagenet', include_top=False,
                          input_shape=input_shape)
        base_model.trainable = False

        model = models.Sequential([
            base_model,
            layers.Flatten(),
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(num_classes, activation='softmax')
        ])

        return model

    @staticmethod
    def build_resnet50(input_shape=(227, 227, 3), num_classes=3):
        base_model = ResNet50(weights='imagenet', include_top=False,
                             input_shape=input_shape)
        base_model.trainable = False

        model = models.Sequential([
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(num_classes, activation='softmax')
        ])

        return model

"""**MODEL TRAINING AND EVALUATION**"""

class ModelTrainer:
    """Handles model compilation, training, and evaluation"""

    def __init__(self, model, model_name):
        self.model = model
        self.model_name = model_name
        self.history = None

    def compile_model(self, learning_rate=0.001):
        """Compile model with optimizer and loss function"""
        self.model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

    def train(self, X_train, y_train, X_val, y_val,
              epochs=50, batch_size=32, use_augmentation=True):
        """Train the model with callbacks"""

        # Data Augmentation
        if use_augmentation:
            datagen = ImageDataGenerator(
                rotation_range=20,
                width_shift_range=0.2,
                height_shift_range=0.2,
                horizontal_flip=True,
                zoom_range=0.2,
                shear_range=0.2,
                fill_mode='nearest'
            )
            datagen.fit(X_train)

        # Callbacks
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7),
            ModelCheckpoint(f'{self.model_name}_best.h5', save_best_only=True,
                          monitor='val_accuracy', mode='max')
        ]

        # Training
        if use_augmentation:
            self.history = self.model.fit(
                datagen.flow(X_train, y_train, batch_size=batch_size),
                validation_data=(X_val, y_val),
                epochs=epochs,
                callbacks=callbacks,
                verbose=1
            )
        else:
            self.history = self.model.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=epochs,
                batch_size=batch_size,
                callbacks=callbacks,
                verbose=1
            )

        return self.history

    def evaluate(self, X_test, y_test):
        """Evaluate model on test set"""
        test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"\n{self.model_name} Test Results:")
        print(f"Test Loss: {test_loss:.4f}")
        print(f"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")

        return test_loss, test_accuracy

    def predict(self, X):
        """Make predictions"""
        return self.model.predict(X)

"""**VISUALIZATION FUNCTIONS**"""

class Visualizer:
    """Visualization utilities for model performance"""

    @staticmethod
    def plot_training_history(history, model_name):
        """Plot training and validation accuracy/loss"""
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # Accuracy plot
        axes[0].plot(history.history['accuracy'], label='Train Accuracy')
        axes[0].plot(history.history['val_accuracy'], label='Val Accuracy')
        axes[0].set_title(f'{model_name} - Accuracy')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Accuracy')
        axes[0].legend()
        axes[0].grid(True)

        # Loss plot
        axes[1].plot(history.history['loss'], label='Train Loss')
        axes[1].plot(history.history['val_loss'], label='Val Loss')
        axes[1].set_title(f'{model_name} - Loss')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Loss')
        axes[1].legend()
        axes[1].grid(True)

        plt.tight_layout()
        plt.savefig(f'{model_name}_training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_names, model_name):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)

        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names)
        plt.title(f'{model_name} - Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.savefig(f'{model_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()

        return cm

    @staticmethod
    def plot_sample_predictions(X_test, y_test, y_pred, class_names, num_samples=12):
        """Plot sample predictions"""
        indices = np.random.choice(len(X_test), num_samples, replace=False)

        fig, axes = plt.subplots(3, 4, figsize=(15, 10))
        axes = axes.ravel()

        for i, idx in enumerate(indices):
            axes[i].imshow(X_test[idx])
            true_label = class_names[y_test[idx]]
            pred_label = class_names[y_pred[idx]]
            color = 'green' if y_test[idx] == y_pred[idx] else 'red'
            axes[i].set_title(f'True: {true_label}\nPred: {pred_label}',
                            color=color, fontsize=10)
            axes[i].axis('off')

        plt.tight_layout()
        plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')
        plt.show()

    @staticmethod
    def compare_models(results_dict):
        """Compare multiple models"""
        models = list(results_dict.keys())
        accuracies = [results_dict[m]['accuracy'] for m in models]

        plt.figure(figsize=(10, 6))
        bars = plt.bar(models, accuracies, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])
        plt.title('Model Comparison - Test Accuracy', fontsize=14, fontweight='bold')
        plt.ylabel('Accuracy', fontsize=12)
        plt.ylim([0, 1.0])

        # Add value labels on bars
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.4f}',
                    ha='center', va='bottom', fontsize=10)

        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()

"""**MAIN EXECUTION PIPELINE**"""

def main(data_dir='potato_leaf_dataset'):
    """
    Main execution pipeline for potato disease detection

    Args:
        data_dir: Path to dataset directory
    """

    print("="*70)
    print("POTATO LEAF DISEASE DETECTION PROJECT")
    print("="*70)

    # Step 1: Load and prepare data
    print("\n[STEP 1] Loading and preparing dataset...")
    loader = PotatoDataLoader(data_dir, img_size=(227, 227))
    (X_train, y_train), (X_val, y_val), (X_test, y_test), label_encoder = loader.prepare_data()
    class_names = label_encoder.classes_

    # Step 2: Build models
    print("\n[STEP 2] Building models...")
    models_dict = {
        'AlexNet': AlexNet.build(num_classes=len(class_names)),
        'CustomCNN': CustomCNN.build(num_classes=len(class_names)),
        'VGG16': TransferLearningModels.build_vgg16(num_classes=len(class_names)),
        'ResNet50': TransferLearningModels.build_resnet50(num_classes=len(class_names))
    }

    # Display AlexNet architecture
    print("\nAlexNet Architecture:")
    models_dict['AlexNet'].summary()

    # Step 3: Train and evaluate all models
    results = {}

    for model_name, model in models_dict.items():
        print(f"\n{'='*70}")
        print(f"[STEP 3] Training {model_name}...")
        print(f"{'='*70}")

        trainer = ModelTrainer(model, model_name)
        trainer.compile_model(learning_rate=0.0001)

        # Train model
        history = trainer.train(
            X_train, y_train, X_val, y_val,
            epochs=30, batch_size=32, use_augmentation=True
        )

        # Evaluate on test set
        test_loss, test_accuracy = trainer.evaluate(X_test, y_test)

        # Get predictions
        y_pred_probs = trainer.predict(X_test)
        y_pred = np.argmax(y_pred_probs, axis=1)

        # Store results
        results[model_name] = {
            'model': model,
            'history': history,
            'accuracy': test_accuracy,
            'loss': test_loss,
            'predictions': y_pred
        }

        # Visualize training history
        Visualizer.plot_training_history(history, model_name)

        # Plot confusion matrix
        Visualizer.plot_confusion_matrix(y_test, y_pred, class_names, model_name)

        # Print classification report
        print(f"\n{model_name} Classification Report:")
        print(classification_report(y_test, y_pred, target_names=class_names))

    # Step 4: Compare all models
    print("\n[STEP 4] Comparing all models...")
    Visualizer.compare_models(results)

    # Step 5: Show sample predictions (using best model)
    best_model_name = max(results, key=lambda k: results[k]['accuracy'])
    print(f"\nBest Model: {best_model_name} with accuracy: {results[best_model_name]['accuracy']:.4f}")

    Visualizer.plot_sample_predictions(
        X_test, y_test,
        results[best_model_name]['predictions'],
        class_names
    )

    # Step 6: Save results summary
    print("\n[STEP 5] Saving results summary...")
    results_df = pd.DataFrame({
        'Model': list(results.keys()),
        'Test Accuracy': [results[m]['accuracy'] for m in results.keys()],
        'Test Loss': [results[m]['loss'] for m in results.keys()]
    })
    results_df = results_df.sort_values('Test Accuracy', ascending=False)
    results_df.to_csv('model_results_summary.csv', index=False)
    print("\nResults Summary:")
    print(results_df)

    print("\n" + "="*70)
    print("PROJECT COMPLETED SUCCESSFULLY!")
    print("="*70)

    return results, class_names

"""** INFERENCE FUNCTION FOR NEW IMAGES**"""

def predict_disease(image_path, model, label_encoder, img_size=(227, 227)):
    """
    Predict disease for a single image

    Args:
        image_path: Path to image file
        model: Trained model
        label_encoder: Label encoder for class names
        img_size: Image size for model input

    Returns:
        Predicted class and confidence
    """
    # Load and preprocess image
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, img_size)
    img = img.astype('float32') / 255.0
    img = np.expand_dims(img, axis=0)

    # Predict
    prediction = model.predict(img, verbose=0)
    class_idx = np.argmax(prediction[0])
    confidence = prediction[0][class_idx]
    class_name = label_encoder.classes_[class_idx]

    # Display result
    plt.figure(figsize=(8, 6))
    plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))
    plt.title(f'Prediction: {class_name}\nConfidence: {confidence:.2%}',
             fontsize=14, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    plt.show()

    return class_name, confidence

# EXECUTION
if __name__ == "__main__":
    # Specify your dataset path
    DATASET_PATH = '/content/Potato'  # Change this to your dataset path

    # Run main pipeline
    results, class_names = main(DATASET_PATH)

    # Example: Predict on a new image (uncomment to use)
    # best_model = results['AlexNet']['model']
    # prediction, confidence = predict_disease(
    #     'path_to_your_image.jpg',
    #     best_model,
    #     label_encoder
    # )

